{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counterfactual - Rung 3 in the Ladder of Causation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Francisco\\anaconda3\\envs\\thesis\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fitting causal mechanism of node Y: 100%|██████████| 4/4 [00:00<00:00, 85.05it/s]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dowhy import gcm\n",
    "from typing import Dict, List, Tuple\n",
    "from itertools import combinations\n",
    "\n",
    "# Step 1: Define the causal model and generate data\n",
    "# Key Attribute of invertible SCM - invertible with respect to noise: noise can be reconstructed from the observed data\n",
    "causal_graph = nx.DiGraph([('A', 'C'), ('B', 'C'), ('C', 'Y')])\n",
    "causal_model = gcm.InvertibleStructuralCausalModel(causal_graph)\n",
    "\n",
    "# Generate some data\n",
    "rng = np.random.default_rng(42)\n",
    "n_samples = 1000\n",
    "A = rng.normal(0, 0.5, size=n_samples)\n",
    "B = rng.normal(0, 0.5, size=n_samples)\n",
    "C = A + 10 * B + rng.normal(0, 0.5, size=n_samples)\n",
    "Y = 2 * C + rng.normal(0, 0.5, size=n_samples)\n",
    "## Setup some training data\n",
    "training_data = pd.DataFrame({'A': A, 'B': B, 'C': C, 'Y': Y})\n",
    "\n",
    "# Set up and fit the causal model (learn the generative model)\n",
    "## By using gcm.EmpiricalDistribution() and gcm.AdditiveNoiseModel(gcm.ml.create_linear_regressor()), we manually assign the causal mechanism\n",
    "# Alternatively  \n",
    "# gcm.auto.assign_causal_mechanisms(causal_model, data)\n",
    "causal_model.set_causal_mechanism('A', gcm.EmpiricalDistribution())\n",
    "causal_model.set_causal_mechanism('B', gcm.EmpiricalDistribution())\n",
    "causal_model.set_causal_mechanism('C', gcm.AdditiveNoiseModel(gcm.ml.create_linear_regressor()))\n",
    "causal_model.set_causal_mechanism('Y', gcm.AdditiveNoiseModel(gcm.ml.create_linear_regressor()))\n",
    "gcm.fit(causal_model, training_data)\n",
    "\n",
    "# Step 2: Compute control values\n",
    "def compute_control_values(data: pd.DataFrame) -> Dict[str, float]:\n",
    "    return {col: np.median(data[col]) for col in data.columns} # we use the median value of the data as favorable event\n",
    "\n",
    "## vector comprising of the control values\n",
    "control_values = compute_control_values(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Counterfactual prediction function of the target variable for one intervention \n",
    "def counterfactual_prediction(causal_model: gcm.InvertibleStructuralCausalModel, \n",
    "                              observed_instance: pd.DataFrame, \n",
    "                              intervention: Dict[str, callable], \n",
    "                              target: str) -> float:\n",
    "    cf_samples = gcm.counterfactual_samples(causal_model, intervention, observed_data=observed_instance)\n",
    "    return cf_samples[target].values[0]\n",
    "\n",
    "# Step 4: Calculate attribution scores\n",
    "def calculate_attribution_scores(causal_model: gcm.InvertibleStructuralCausalModel, \n",
    "                                 observed_instance: pd.DataFrame, \n",
    "                                 control_values: Dict[str, float], \n",
    "                                 target: str) -> Dict[str, float]:\n",
    "    scores = {}\n",
    "    for variable in causal_model.graph.nodes:\n",
    "        # Compute counterfactual for each node except target node (score)\n",
    "        if variable != target:\n",
    "            intervention = {variable: lambda x: control_values[variable]}\n",
    "            cf_prediction = counterfactual_prediction(causal_model, observed_instance, intervention, target)\n",
    "            # Absolute deviation from control value\n",
    "            scores[variable] = abs(cf_prediction - control_values[target])\n",
    "    return scores\n",
    "\n",
    "# Step 5: Identify similarity groups\n",
    "def identify_similarity_groups(scores: Dict[str, float], similarity_threshold: float) -> List[List[str]]:\n",
    "    sorted_vars = sorted(scores.keys(), key=lambda x: scores[x])  # Sort from lowest to highest score, key specifies what should be compared for sorting\n",
    "    groups = []\n",
    "    current_group = [sorted_vars[0]]\n",
    "    \n",
    "    for var in sorted_vars[1:]:\n",
    "        if abs(scores[var] - scores[current_group[0]]) <= similarity_threshold:\n",
    "            current_group.append(var)\n",
    "        else:\n",
    "            groups.append(current_group)\n",
    "            current_group = [var]\n",
    "    \n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "    \n",
    "    return groups\n",
    "\n",
    "# Step 6: Find earliest ancestor\n",
    "def find_earliest_ancestor(group: List[str], causal_graph: nx.DiGraph) -> str:\n",
    "    ancestors = set(group)\n",
    "    for node in group:\n",
    "        ancestors &= set(nx.ancestors(causal_graph, node)) | {node} #retrieves path up to node\n",
    "    return min(ancestors, key=lambda x: list(causal_graph.nodes()).index(x)) # returns earliest member from ancestors set\n",
    "\n",
    "# Step 7: Disentangle scores for each group\n",
    "def disentangle_scores(scores: Dict[str, float], \n",
    "                       similarity_groups: List[List[str]], \n",
    "                       causal_graph: nx.DiGraph) -> Dict[str, float]:\n",
    "    disentangled_scores = {}\n",
    "    for group in similarity_groups:\n",
    "        earliest_ancestor = find_earliest_ancestor(group, causal_graph)\n",
    "        disentangled_scores[earliest_ancestor] = scores[earliest_ancestor]\n",
    "    return disentangled_scores\n",
    "\n",
    "# Step 8: Counterfactual Root Cause Analysis\n",
    "def counterfactual_rca(causal_model: gcm.InvertibleStructuralCausalModel, \n",
    "                       observed_instance: pd.DataFrame, \n",
    "                       control_values: Dict[str, float], \n",
    "                       target: str, \n",
    "                       similarity_threshold: float) -> Tuple[str, Dict[str, float]]:\n",
    "    # Calculate attribution scores\n",
    "    scores = calculate_attribution_scores(causal_model, observed_instance, control_values, target)\n",
    "    \n",
    "    # Identify similarity groups\n",
    "    similarity_groups = identify_similarity_groups(scores, similarity_threshold)\n",
    "    \n",
    "    # Disentangle scores\n",
    "    disentangled_scores = disentangle_scores(scores, similarity_groups, causal_model.graph)\n",
    "    \n",
    "    # Identify root cause (now minimizing the score)\n",
    "    root_cause = min(disentangled_scores, key=disentangled_scores.get)\n",
    "    \n",
    "    return root_cause, disentangled_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing event_a:\n",
      "Identified root cause: C\n",
      "Disentangled scores (lower is more causal):\n",
      "C: 2.952756090215799\n",
      "B: 10.705453547260689\n",
      "A: 11.081312757094434\n",
      "\n",
      "Analyzing event_b:\n",
      "Identified root cause: B\n",
      "Disentangled scores (lower is more causal):\n",
      "B: 2.7320768140865006\n",
      "C: 2.952756090215799\n",
      "A: 11.596372904659507\n",
      "\n",
      "Analyzing event_c:\n",
      "Identified root cause: C\n",
      "Disentangled scores (lower is more causal):\n",
      "C: 2.952756090215799\n",
      "B: 10.705453547260692\n",
      "A: 11.59637290465951\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the algorithm with the provided events\n",
    "events = {\n",
    "    'event_a': {'A': 1.00, 'B': 0.1, 'C': 4.75, 'Y': 12.5},\n",
    "    'event_b': {'A': 0.75, 'B': 0.5, 'C': 4.75, 'Y': 12.5},\n",
    "    'event_c': {'A': 0.75, 'B': 0.1, 'C': 4.75, 'Y': 12.5}\n",
    "}\n",
    "\n",
    "for event_name, event_data in events.items():\n",
    "    print(f\"\\nAnalyzing {event_name}:\")\n",
    "    observed_instance = pd.DataFrame([event_data])\n",
    "    root_cause, disentangled_scores = counterfactual_rca(causal_model, observed_instance, control_values, 'Y', similarity_threshold=0.1)\n",
    "    print(f\"Identified root cause: {root_cause}\")\n",
    "    print(\"Disentangled scores (lower is more causal):\")\n",
    "    for var, score in sorted(disentangled_scores.items(), key=lambda x: x[1]):\n",
    "        print(f\"{var}: {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
