{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Thesis - Simulated Pick and Place Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules imported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The required modules need to be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coppeliasim_zmqremoteapi_client import RemoteAPIClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from graphviz import Digraph\n",
    "\n",
    "# silencing due downcasting warning to pandas.DataFrame.replace() \n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collection of custom functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace True and False with 1 and 0, adjust for NaNs\n",
    "def data_process(data : pd.DataFrame):\n",
    "    return data.replace(np.nan, 0).replace({True: 1, False: 0})\n",
    "\n",
    "# Save raw Data\n",
    "def data_save_raw(data : pd.DataFrame,run_number:int,timestamp):\n",
    "    main_dir = 'G:\\My Drive\\Master Thesis\\Simulation\\Datasets_raw'  # main directory name\n",
    "    folder_name = f'Dataset_{run_number}_{timestamp}'\n",
    "    name = get_var_name(data)\n",
    "    filename = f'{name}.csv'\n",
    "    folder_path = os.path.join(main_dir, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    data.to_csv(os.path.join(folder_path, filename), index=False)\n",
    "    return [filename,folder_path]\n",
    "\n",
    "# Save Data\n",
    "def data_save_all(data: pd.DataFrame,run_number:int,type:str,timestamp):\n",
    "    main_dir = 'G:\\My Drive\\Master Thesis\\Simulation\\Dataset'  # main directory name\n",
    "    folder_name = f'Dataset_{timestamp}'\n",
    "    filename = f'data_{run_number}_{type}.csv'\n",
    "    folder_path = os.path.join(main_dir, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    data.to_csv(os.path.join(folder_path, filename), index=False)\n",
    "    return [filename,folder_path]\n",
    "\n",
    "# Retrieve the variable name for saving\n",
    "def get_var_name(var):\n",
    "    for name, value in globals().items():\n",
    "        if value is var:\n",
    "            return name[:-3]\n",
    "        \n",
    "# Read raw data, return combined dataset   \n",
    "def data_read_save(files):\n",
    "\n",
    "    # Adjust column names, to match node names\n",
    "    camera_1 = pd.read_csv(files[0][1] + '/' + files[0][0])\n",
    "    camera_1 = camera_1[['sizeX','sizeY']]\n",
    "    camera_1 = camera_1.rename(columns={'sizeX': 'cam_1_X','sizeY': 'cam_1_Y'})\n",
    "\n",
    "    camera_2 = pd.read_csv(files[1][1] + '/' + files[1][0])\n",
    "    camera_2 = camera_2[['sizeX','sizeY']]\n",
    "    camera_2 = camera_2.rename(columns={'sizeX': 'cam_2_X','sizeY': 'cam_2_Y'})\n",
    "\n",
    "    data_out = pd.concat([camera_1,camera_2],axis=1)\n",
    "\n",
    "    camera_3 = pd.read_csv(files[2][1] + '/' + files[2][0])\n",
    "    camera_3 = camera_3[['sizeX','sizeY']]\n",
    "    camera_3 = camera_3.rename(columns={'sizeX': 'cam_3_X','sizeY': 'cam_3_Y'})\n",
    "\n",
    "    data_out = pd.concat([data_out,camera_3],axis=1)\n",
    "\n",
    "    camera_EoL = pd.read_csv(files[3][1] + '/' + files[3][0])\n",
    "    camera_EoL = camera_EoL[['part1SizeX','part2SizeX','part3SizeX','part4SizeX',\n",
    "                             'part1SizeY','part2SizeY','part3SizeY','part4SizeY',\n",
    "                             'tray1SizeX','tray1SizeY','tray2SizeX','tray2SizeY', 'id']]\n",
    "    \n",
    "    camera_EoL = camera_EoL.rename(columns={'part1SizeX':'EoL_3_X','part2SizeX':'EoL_4_X','part3SizeX':'EoL_5_X','part4SizeX':'EoL_6_X',\n",
    "                                            'part1SizeY':'EoL_3_Y','part2SizeY':'EoL_4_Y','part3SizeY':'EoL_5_Y', 'part4SizeY':'EoL_6_Y',\n",
    "                                            'tray1SizeX':'EoL_1_X','tray1SizeY':'EoL_1_Y',\n",
    "                                            'tray2SizeX':'EoL_2_X','tray2SizeY':'EoL_2_Y',\n",
    "                                            'id':'product_id'})\n",
    "    \n",
    "    EoL_nodes = ['EoL_1_X', 'EoL_1_Y',\n",
    "             'EoL_2_X', 'EoL_2_Y',\n",
    "             'EoL_3_X', 'EoL_3_Y',\n",
    "             'EoL_4_X', 'EoL_4_Y',\n",
    "             'EoL_5_X','EoL_5_Y',\n",
    "             'EoL_6_X', 'EoL_6_Y']\n",
    "    \n",
    "    scores = []\n",
    "\n",
    "    for index, row in camera_EoL.iterrows():\n",
    "        non_zero_count = (row != 0).sum()\n",
    "        total_count = len(EoL_nodes)\n",
    "        score = (non_zero_count / total_count) * 100\n",
    "        scores.append(score)\n",
    "\n",
    "    camera_EoL['score'] = scores\n",
    "\n",
    "    data_out = pd.concat([data_out,camera_EoL],axis=1)\n",
    "\n",
    "    conveyor_1 = pd.read_csv(files[4][1] + '/' + files[4][0])\n",
    "    conveyor_1 = conveyor_1[['speed']]\n",
    "    conveyor_1 = conveyor_1.rename(columns={'speed':'con_1'})\n",
    "\n",
    "    data_out = pd.concat([data_out,conveyor_1],axis=1)\n",
    "\n",
    "    conveyor_2 = pd.read_csv(files[5][1] + '/' + files[5][0])\n",
    "    conveyor_2 = conveyor_2[['speed']]\n",
    "    conveyor_2 = conveyor_2.rename(columns={'speed':'con_2'})\n",
    "\n",
    "    data_out = pd.concat([data_out,conveyor_2],axis=1)\n",
    "\n",
    "    conveyor_3 = pd.read_csv(files[6][1] + '/' + files[6][0])\n",
    "    conveyor_3 = conveyor_3[['speed']]\n",
    "    conveyor_3 = conveyor_3.rename(columns={'speed':'con_3'})\n",
    "\n",
    "    data_out = pd.concat([data_out,conveyor_3],axis=1)\n",
    "\n",
    "    rob_1 = pd.read_csv(files[7][1] + '/' + files[7][0])\n",
    "    rob_1 = rob_1[['jointVelo1','jointVelo2', 'jointVelo4',\t'maxVel','gripperSupply','gripperVacuum','jointVelo3']]\n",
    "    rob_1 = rob_1.rename(columns={'jointVelo1':'rob_1_1','jointVelo2':'rob_1_2','jointVelo3':'rob_1_3','jointVelo4':'rob_1_4',\n",
    "                                  'maxVel':'rob_1_maxVel','gripperSupply':'rob_1_supply','gripperVacuum':'rob_1_vacuum'})\n",
    "    \n",
    "    data_out = pd.concat([data_out,rob_1],axis=1)\n",
    "    \n",
    "    rob_2 = pd.read_csv(files[8][1] + '/' + files[8][0])\n",
    "    rob_2 = rob_2[['jointVelo1','jointVelo2', 'jointVelo4',\t'maxVel','gripperSupply','gripperVacuum','jointVelo3']]\n",
    "    rob_2 = rob_2.rename(columns={'jointVelo1':'rob_2_1','jointVelo2':'rob_2_2','jointVelo3':'rob_2_3','jointVelo4':'rob_2_4',\n",
    "                                  'maxVel':'rob_2_maxVel','gripperSupply':'rob_2_supply','gripperVacuum':'rob_2_vacuum'})\n",
    "    \n",
    "    data_out = pd.concat([data_out,rob_2],axis=1)\n",
    "\n",
    "    events_out = pd.read_csv(files[9][1] + '/' + files[9][0])\n",
    "\n",
    "    \n",
    "    return data_out,events_out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection to Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish connection to the Simulation (locally running) and retrieve specific object handles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client enabling  connection to the Simulation\n",
    "client = RemoteAPIClient()\n",
    "\n",
    "# Get the libraries used by the simulation software\n",
    "sim = client.require('sim')\n",
    "simBWF = client.require('simBWF')\n",
    "\n",
    "inter_script = sim.getObject('/Interventions')\n",
    "\n",
    "camera_1 = sim.getObject('/camera_1/camera')\n",
    "camera_2 = sim.getObject('/camera_2/camera')\n",
    "camera_3 = sim.getObject('/camera_3/camera')\n",
    "camera_EoL = sim.getObject('/camera_EoL/camera')\n",
    "\n",
    "conveyor1 = sim.getObject('/genericConveyorTypeA[0]')\n",
    "conveyor2 = sim.getObject('/genericConveyorTypeA[2]')\n",
    "conveyor3 = sim.getObject('/genericConveyorTypeA[1]')\n",
    "\n",
    "rob_1 = sim.getObject('/Ragnar[0]')\n",
    "rob_2 = sim.getObject('/Ragnar[1]')\n",
    "\n",
    "events = sim.getObject('/Events')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup: Simulation, runs and interventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the setup and configure the Simulation, the various runs and which interventions to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collection of all predefined interventions\n",
    "inter = {'gripper_1':'interGripper1',\n",
    "         'gripper_2':'interGripper2',\n",
    "         'max_Vel_1':'interVeloRob1',\n",
    "         'max_Vel_2':'interVeloRob2',\n",
    "         'camera_1':'interCamera1',\n",
    "         'camera_2':'interCamera2',\n",
    "         'camera_3':'interCamera3',\n",
    "         'conveyor_1':'interConveyor1',\n",
    "         'conveyor_2':'interConveyor2',\n",
    "         'conveyor_3':'interConveyor3',\n",
    "         'feeder_1':'interFeeder1',\n",
    "         'feeder_2':'interFeeder2',\n",
    "         'feeder_3':'interFeeder3',\n",
    "         'size_1':'interSize1',\n",
    "         'size_2':'interSize2',\n",
    "         'size_3':'interSize3',}\n",
    "\n",
    "# Setup of runs to be used\n",
    "run_1 ={'type':'normal'}\n",
    "run_2 ={'type':'size_1'}\n",
    "run_3 ={'type':'feeder_3'}\n",
    "run_4 ={'type':'gripper_1'}\n",
    "run_5 ={'type':'max_Vel_2'}\n",
    "\n",
    "# Configure simulation and which runs to perform\n",
    "simulation = [run_1, run_4, run_1, run_2] \n",
    "\n",
    "# Configure ob 1 single set of items should be drop or not\n",
    "single_drop = False\n",
    "\n",
    "# Configure duration of Simulation in seconds\n",
    "duration = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n"
     ]
    }
   ],
   "source": [
    "run_count = 0\n",
    "\n",
    "# Start timestamp of each simulation\n",
    "now = datetime.datetime.now()\n",
    "timestamp = now.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "# Iterate over all runs in Simulation\n",
    "for run in simulation:\n",
    "    \n",
    "    # Establish containers for the data\n",
    "    camera_1_df = pd.DataFrame()\n",
    "    camera_2_df = pd.DataFrame()\n",
    "    camera_3_df = pd.DataFrame()\n",
    "    camera_EoL_df = pd.DataFrame()\n",
    "\n",
    "    conveyor_1_df = pd.DataFrame()\n",
    "    conveyor_2_df = pd.DataFrame()\n",
    "    conveyor_3_df = pd.DataFrame()\n",
    "\n",
    "    rob_1_df = pd.DataFrame()\n",
    "    rob_2_df = pd.DataFrame()\n",
    "\n",
    "    for type,value in run.items():\n",
    "        run_count+=1\n",
    "\n",
    "        # retrieve run type - interventional or normal\n",
    "        if value != 'normal':\n",
    "            sim.callScriptFunction(inter[value],sim.getScript(sim.scripttype_customizationscript, inter_script))\n",
    "        \n",
    "        # assemble one single set\n",
    "        if single_drop:\n",
    "            sim.callScriptFunction('interFeederAll',sim.getScript(sim.scripttype_customizationscript, inter_script))\n",
    "\n",
    "        # show which type is currently running\n",
    "        print(value)\n",
    "\n",
    "        # Activate Stepping-mode, means run according to simulation timestep \n",
    "        sim.setStepping(True)\n",
    "\n",
    "        # Start of Simulation\n",
    "        sim.startSimulation()\n",
    "        \n",
    "        # Disable Visualisation, for better performance\n",
    "        sim.setBoolParam(sim.boolparam_display_enabled, False)\n",
    "\n",
    "        while (t := sim.getSimulationTime()) < duration  : # Execute Data Collection while condition not fulfilled\n",
    "            \n",
    "            # Retrieve data from simulation by accessing the customData-Tables formatted in CoppeliaSim\n",
    "            camera_1_data = pd.DataFrame([sim.unpackTable(sim.readCustomDataBlock(camera_1,'customData'))])\n",
    "            camera_2_data = pd.DataFrame([sim.unpackTable(sim.readCustomDataBlock(camera_2,'customData'))])\n",
    "            camera_3_data = pd.DataFrame([sim.unpackTable(sim.readCustomDataBlock(camera_3,'customData'))])\n",
    "            camera_EoL_data = pd.DataFrame([sim.unpackTable(sim.readCustomDataBlock(camera_EoL,'customData'))])\n",
    "\n",
    "            conveyor_1_data = pd.DataFrame([sim.unpackTable(sim.readCustomDataBlock(conveyor1, 'customData'))])\n",
    "            conveyor_2_data = pd.DataFrame([sim.unpackTable(sim.readCustomDataBlock(conveyor2, 'customData'))])\n",
    "            conveyor_3_data = pd.DataFrame([sim.unpackTable(sim.readCustomDataBlock(conveyor3, 'customData'))])\n",
    "\n",
    "            rob_1_data = pd.DataFrame([sim.unpackTable(sim.readCustomDataBlock(rob_1,'customData'))])\n",
    "            rob_2_data = pd.DataFrame([sim.unpackTable(sim.readCustomDataBlock(rob_2,'customData'))])\n",
    "            \n",
    "            # Fill containers\n",
    "            camera_1_df= pd.concat([camera_1_df,camera_1_data], ignore_index=True)\n",
    "            camera_2_df= pd.concat([camera_2_df,camera_2_data], ignore_index=True)\n",
    "            camera_3_df= pd.concat([camera_3_df,camera_3_data], ignore_index=True)\n",
    "            camera_EoL_df= pd.concat([camera_EoL_df,camera_EoL_data], ignore_index=True)\n",
    "\n",
    "            conveyor_1_df= pd.concat([conveyor_1_df,conveyor_1_data], ignore_index=True)\n",
    "            conveyor_2_df= pd.concat([conveyor_2_df,conveyor_2_data], ignore_index=True)\n",
    "            conveyor_3_df= pd.concat([conveyor_3_df,conveyor_3_data], ignore_index=True)\n",
    "\n",
    "            rob_1_df = pd.concat([rob_1_df,rob_1_data], ignore_index=True)\n",
    "            rob_2_df = pd.concat([rob_2_df,rob_2_data], ignore_index=True)\n",
    "\n",
    "            # Necessary for stepping-mode, otherwise simulation would get stuck\n",
    "            sim.step()\n",
    "\n",
    "        # Finish, when duration is full\n",
    "        sim.stopSimulation()\n",
    "\n",
    "        # Events are looged internally by CoppeliaSim, thus we extract per run the entire log-File associated to the events.\n",
    "        events_df = pd.DataFrame(sim.unpackTable(sim.readCustomDataBlock(events,'customData')))\n",
    "    \n",
    "        # Data processing - True,False and NaN\n",
    "        camera_1_df = data_process(camera_1_df)\n",
    "        camera_2_df = data_process(camera_2_df)\n",
    "        camera_3_df = data_process(camera_3_df)\n",
    "        camera_EoL_df = data_process(camera_EoL_df)\n",
    "\n",
    "        conveyor_1_df = data_process(conveyor_1_df)\n",
    "        conveyor_2_df = data_process(conveyor_2_df)\n",
    "        conveyor_3_df = data_process(conveyor_3_df)\n",
    "\n",
    "        rob_1_df = data_process(rob_1_df)\n",
    "        rob_2_df = data_process(rob_2_df)\n",
    "        events_df = data_process(events_df)\n",
    "\n",
    "        # Save all files\n",
    "        files = [\n",
    "                    data_save_raw(camera_1_df, run_count,timestamp),\n",
    "                    data_save_raw(camera_2_df, run_count,timestamp),\n",
    "                    data_save_raw(camera_3_df, run_count,timestamp),\n",
    "                    data_save_raw(camera_EoL_df, run_count,timestamp),\n",
    "                    data_save_raw(conveyor_1_df, run_count,timestamp),\n",
    "                    data_save_raw(conveyor_2_df, run_count,timestamp),\n",
    "                    data_save_raw(conveyor_3_df, run_count,timestamp),\n",
    "                    data_save_raw(rob_1_df, run_count,timestamp),\n",
    "                    data_save_raw(rob_2_df, run_count,timestamp),\n",
    "                    data_save_raw(events_df, run_count,timestamp),\n",
    "                ]\n",
    "        \n",
    "        data_out,events_out = data_read_save(files)\n",
    "        data = data_save_all(data_out,run_count,value,timestamp)\n",
    "        data_event = data_save_all(events_out,run_count,'event',timestamp)\n",
    "        \n",
    "        # Some time for the simulation to stop before starting again\n",
    "        time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
